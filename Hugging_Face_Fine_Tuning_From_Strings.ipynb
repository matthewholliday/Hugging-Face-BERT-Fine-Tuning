{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hugging-Face-Fine-Tuning-From-Strings.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdWfJmaPHlWom0qdnZHLvk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewholliday/Hugging-Face-BERT-Fine-Tuning/blob/main/Hugging_Face_Fine_Tuning_From_Strings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "cIa35oY1eVYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgPqkd_bdr8s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"bert-base-uncased\" #Name of the checkpoint"
      ],
      "metadata": {
        "id": "d8_5W2TQeN9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint) #Initialize the tokenizer from the checkpoint."
      ],
      "metadata": {
        "id": "LfH0OvJueoXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint) #Initialize the model from the checkpoint."
      ],
      "metadata": {
        "id": "J5yKff7ferkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**These are the sentences we will be fine-tuning the model with:**"
      ],
      "metadata": {
        "id": "4OQZTmQmfmJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"This course is amazing!\",\n",
        "]"
      ],
      "metadata": {
        "id": "NJ8OSNGbexfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting the raw sentences into a trainable tensor format:**\n",
        "*   We pad the tensor with the padding_token_id to give it a \"rectangular\" shape.\n",
        "*   We truncate the input to make sure that it's length does not exceed what the model is capable of."
      ],
      "metadata": {
        "id": "wrYePa-2fGBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = dict(tokenizer(sequences, padding=True, truncation=True, return_tensors=\"tf\"))"
      ],
      "metadata": {
        "id": "-2zs9h4Xe7sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
        "labels = tf.convert_to_tensor([1, 1])\n",
        "model.train_on_batch(batch, labels)"
      ],
      "metadata": {
        "id": "DbUWEseJe_YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jEGJSEM0fCLe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}